  

# üìã RESUMO  DE ARTEFATOS - MH-AutoML

  

## üßÆ Resumo

Este documento apresenta uma an√°lise detalhada dos principais artefatos gerados pelo pipeline MH-AutoML, uma solu√ß√£o desenvolvida para a detec√ß√£o de malware em aplica√ß√µes Android. Os resultados e as configura√ß√µes aqui descritas s√£o baseados em um conjunto de dados de teste, composto por **15.036 amostras e 51 caracter√≠sticas**.

O dataset reflete um cen√°rio realista de distribui√ß√£o de classes, onde a propor√ß√£o de amostras benignas √© naturalmente maior que a de malwares, apresentando **63.01% de amostras benignas e 36.99% de amostras maliciosas**. Essa caracter√≠stica do conjunto de dados √© fundamental para avaliar a capacidade do modelo em lidar com a assimetria comum em problemas de detec√ß√£o de amea√ßas.

Al√©m das visualiza√ß√µes gr√°ficas que ilustram cada etapa do processo, o pipeline tamb√©m gera arquivos CSV e um modelo serializado, que registram escolhas e resultados cruciais. Ao longo das se√ß√µes seguintes, ser√£o abordadas as etapas cruciais do processo de Machine Learning:

-   **Pr√©-processamento dos dados:** Com destaque para a an√°lise de valores faltantes.
    
-   **Engenharia de caracter√≠sticas:** Incluindo a sele√ß√£o de features via LASSO e ANOVA, e a redu√ß√£o de dimensionalidade com PCA. Al√©m disso, arquivos como `Features_Selected_20250701_232221.csv` e `treino_20250701_232146.csv` fornecem o registro exato das caracter√≠sticas selecionadas e dos dados utilizados no treinamento.
    
-   **Otimiza√ß√£o do modelo:** Detalhando a import√¢ncia dos hiperpar√¢metros e a curva de otimiza√ß√£o. O arquivo `Hyperparameters_Results.csv` documenta todas as tentativas de otimiza√ß√£o e as m√©tricas de desempenho correspondentes, enquanto `Models_Ranking.csv` oferece uma classifica√ß√£o dos modelos testados.
    
-   **Avalia√ß√£o de desempenho:** Apresentando m√©tricas como matriz de confus√£o, curvas ROC, Precis√£o-Recall e avalia√ß√£o por classe.
    
-   **Interpretabilidade do modelo:** Utilizando t√©cnicas avan√ßadas como SHAP e LIME, al√©m da an√°lise da √°rvore de decis√£o, para garantir a transpar√™ncia e a confiabilidade das previs√µes.
    
-   **Performance geral do pipeline:** Avaliando o consumo de tempo e mem√≥ria RAM por etapa.
    

Cada artefato visual e estat√≠stico ser√° explicado para oferecer uma compreens√£o completa do fluxo de trabalho, das escolhas t√©cnicas e dos resultados alcan√ßados pelo sistema MH-AutoML, incluindo o `best_model_20250701_232146.pkl`, que representa o modelo final otimizado.



## 1. üìä Pr√© Processamento

  

### 1.2 An√°lise de Valores Faltantes

![HEATMAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/missing_values_heatmap.png)

  

**Explica√ß√£o**:


A figura abaixo apresenta um *heatmap* de valores ausentes no conjunto de dados, em que as regi√µes em roxo indicam dados completos, enquanto as regi√µes em amarelo representam valores faltantes. Essa visualiza√ß√£o √© √∫til para identificar padr√µes sistem√°ticos de aus√™ncia, indicando que certas caracter√≠sticas foram coletadas de forma inconsistente entre as amostras.

√â poss√≠vel observar que algumas colunas apresentam uma propor√ß√£o significativa de valores ausentes, o que pode comprometer a performance de modelos de aprendizado de m√°quina. Dessa forma:

- **Caracter√≠sticas com mais de 50% de valores ausentes** devem ser consideradas para remo√ß√£o;
- **Caracter√≠sticas com taxa moderada de aus√™ncia** podem ser tratadas com t√©cnicas de imputa√ß√£o.

  

## 2. ‚öôÔ∏è Engenharia de Features

  

### 2.1 Sele√ß√£o de Caracter√≠sticas LASSO e ANOVA

![LASSO](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/lasso_feature_importance.png)

  

**Explica√ß√£o LASSO**:

O gr√°fico acima apresenta a import√¢ncia das caracter√≠sticas extra√≠da a partir dos coeficientes do modelo LASSO (*Least Absolute Shrinkage and Selection Operator*), que aplica regulariza√ß√£o L1 durante o treinamento. Nesse contexto:

- As **barras azuis** representam caracter√≠sticas com coeficientes positivos, que est√£o positivamente associadas √† classe-alvo (por exemplo, "malware");
- As **barras vermelhas** indicam caracter√≠sticas com coeficientes negativos, associadas √† classe oposta (por exemplo, "benigno").

O valor absoluto do coeficiente indica o peso da influ√™ncia da caracter√≠stica no modelo. Caracter√≠sticas com coeficiente zero foram automaticamente eliminadas pelo LASSO, contribuindo para a sele√ß√£o de um subconjunto mais relevante de atributos e promovendo a interpretabilidade do modelo.

Destacam-se, por exemplo, permiss√µes como `SEND_SMS`, `READ_PHONE_STATE`, `INTERNET` e `READ_SMS`, que apresentaram os maiores coeficientes positivos, sugerindo forte associa√ß√£o com o comportamento malicioso de aplica√ß√µes Android. Esse tipo de an√°lise √© essencial para entender o papel individual de cada atributo no processo de classifica√ß√£o automatizada.
### Import√¢ncia de Caracter√≠sticas com ANOVA

O gr√°fico acima representa os *F-values* obtidos pela aplica√ß√£o do teste estat√≠stico ANOVA (*Analysis of Variance*) para avalia√ß√£o univariada de import√¢ncia de cada caracter√≠stica em rela√ß√£o √† vari√°vel-alvo.

Caracter√≠sticas com valores de F mais altos possuem maior poder discriminativo entre as classes. Diferente do LASSO, que realiza penaliza√ß√µes e sele√ß√£o multivariada, a ANOVA avalia cada atributo de forma independente, oferecendo uma vis√£o estat√≠stica √∫til para filtragem inicial de atributos.

Essa abordagem √© especialmente √∫til em etapas preliminares de sele√ß√£o de caracter√≠sticas, sendo frequentemente combinada com m√©todos de regulariza√ß√£o ou √°rvores de decis√£o para an√°lises mais robustas.
  

### 2.2 Redu√ß√£o de Dimensionalidade PCA

![PCA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/pca_biplot.png)

  

**Explica√ß√£o**:

O gr√°fico apresentado √© um **Biplot de An√°lise de Componentes Principais (PCA)**. Este tipo de visualiza√ß√£o tem como objetivo reduzir a dimensionalidade de um conjunto de dados complexo (neste caso, as permiss√µes de aplicativos) para duas dimens√µes (Componente Principal 1 e Componente Principal 2), que capturam a maior parte da variabilidade dos dados.

O gr√°fico exibe simultaneamente:

1.  **As amostras (pontos):** Cada ponto representa um aplicativo, colorido de acordo com sua classe. Roxo (valor 0) indica um aplicativo **Benigno**, e amarelo (valor 1) indica **Malware**.
    
2.  **As vari√°veis originais (vetores):** As setas vermelhas partindo da origem s√£o os vetores de carga, representando as permiss√µes do sistema (features). A dire√ß√£o e o comprimento de cada vetor indicam como cada permiss√£o influencia os dois componentes principais.
    

**Principais destaques:**

A an√°lise do gr√°fico revela como as permiss√µes (features) se relacionam com as classes de aplicativos (Benigno vs. Malware):

-   **Separa√ß√£o de Classes:** Existe uma tend√™ncia clara de separa√ß√£o entre as classes. Aplicativos **Malware (amarelo)** est√£o concentrados predominantemente no quadrante superior direito, indicando que possuem valores positivos tanto para a Componente Principal 1 quanto para a Componente Principal 2. Aplicativos **Benignos (roxo)** est√£o mais dispersos, mas com uma forte concentra√ß√£o no lado esquerdo do gr√°fico (valores negativos de Componente Principal 1).
    
-   **Influ√™ncia das Permiss√µes:** Os vetores de carga nos mostram as permiss√µes mais influentes:
    
    -   **Fortemente associadas a Malware:** Permiss√µes como `SEND_SMS`, `READ_PHONE_STATE`, `INSTALL_PACKAGES` e `WRITE_SMS` t√™m vetores que apontam para a mesma dire√ß√£o da concentra√ß√£o de malware (direita e para cima). Isso indica que essas permiss√µes s√£o fortes indicadores de um aplicativo malicioso.
        
    -   **Correla√ß√£o entre Permiss√µes:** Os vetores para `SEND_SMS`, `RECEIVE_SMS`, `READ_SMS` e `WRITE_SMS` est√£o muito pr√≥ximos, apontando na mesma dire√ß√£o. Isso sugere que essas permiss√µes s√£o altamente correlacionadas, ou seja, se um aplicativo solicita uma delas, √© muito prov√°vel que solicite as outras tamb√©m.
        

**Interpreta√ß√£o:**

O biplot demonstra que as duas primeiras componentes principais conseguem capturar caracter√≠sticas importantes que distinguem aplicativos benignos de maliciosos.

A **Componente Principal 1** (eixo horizontal) parece ser um forte diferenciador geral. Valores positivos nesta componente, influenciados principalmente por permiss√µes como `READ_PHONE_STATE` e `INSTALL_PACKAGES`, est√£o fortemente associados a malware.

A **Componente Principal 2** (eixo vertical), influenciada principalmente pela permiss√£o `SEND_SMS`, ajuda a refinar essa separa√ß√£o, especialmente para o cluster de malware.

A sobreposi√ß√£o entre os pontos roxos e amarelos indica que apenas com estas duas componentes n√£o √© poss√≠vel separar perfeitamente as duas classes, mas a tend√™ncia √© evidente. O gr√°fico fornece insights valiosos para a engenharia de features, mostrando que um modelo de machine learning provavelmente atribuir√° grande import√¢ncia a permiss√µes como `SEND_SMS` e `READ_PHONE_STATE` para detectar atividades maliciosas. Em resumo, a visualiza√ß√£o confirma que o comportamento de solicita√ß√£o de certas permiss√µes √© um fator crucial para a classifica√ß√£o de malware.

  

### 2.2 Mapa de calor contribui√ß√£o das caracter√≠sticas PCA

![PCA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/pca_components_20250701_212334.png)

  

**Explica√ß√£o**:

O gr√°fico apresentado √© um **mapa de calor (heatmap)** que detalha as contribui√ß√µes (ou "cargas") de cada feature original (permiss√µes de aplicativos, listadas no eixo Y) para cada uma das dez primeiras Componentes Principais (PCs), de PC 1 a PC 10 (listadas no eixo X).

Esta visualiza√ß√£o nos permite entender a "composi√ß√£o" de cada componente principal. A intensidade e a cor de cada c√©lula indicam a for√ßa e a dire√ß√£o da influ√™ncia de uma feature sobre um componente:

-   **Cor Vermelha (valores positivos):** Indica uma contribui√ß√£o positiva. Quando o valor de uma feature com carga positiva aumenta, o escore do componente principal tamb√©m tende a aumentar.
    
-   **Cor Azul (valores negativos):** Indica uma contribui√ß√£o negativa. Quando o valor de uma feature com carga negativa aumenta, o escore do componente principal tende a diminuir.
    
-   **Cor Clara/Branca (valores pr√≥ximos de zero):** Indica que a feature tem pouca ou nenhuma influ√™ncia sobre aquele componente espec√≠fico.
    

**Principais destaques:**

O mapa de calor revela que cada componente principal √© dominado por um pequeno conjunto de features correlacionadas, representando um tipo espec√≠fico de comportamento ou funcionalidade do aplicativo.

-   **Componente Principal 1 (PC 1):** √â fortemente dominada por duas features com cargas positivas muito altas: `ACCESS_NETWORK_STATE_1.0` e `INTERNET_1.0`. Todas as outras features t√™m uma contribui√ß√£o quase nula para este componente.
    
-   **Componente Principal 2 (PC 2):** √â majoritariamente definida pela permiss√£o `SEND_SMS_1.0`, que possui a maior carga positiva. Outras permiss√µes relacionadas a SMS (`RECEIVE_SMS` e `READ_SMS`) tamb√©m contribuem positivamente, mas com menor intensidade.
    
-   **Componente Principal 3 (PC 3):** √â primariamente influenciada positivamente pela permiss√£o `READ_PHONE_STATE_1.0`.
    
-   **Componente Principal 4 (PC 4):** Possui uma forte carga negativa da feature `USE_CREDENTIALS_1.0`.
    
-   **Outros Componentes:** Cada componente subsequente √© definido por outras features. Por exemplo, `PC 5` √© influenciado por `WRITE_SETTINGS_1.0`, e `PC 8` √© negativamente influenciado por `RESTART_PACKAGES_1.0`.
    

**Interpreta√ß√£o:**

Este mapa de calor √© fundamental para interpretar o que cada componente principal representa em termos pr√°ticos. Em vez de analisar dezenas de permiss√µes, podemos entender a variabilidade dos dados atrav√©s de 10 "conceitos" ou "padr√µes de comportamento" independentes.

-   **PC 1 pode ser interpretado como o "Componente de Acesso √† Internet"**. Aplicativos com pontua√ß√£o alta neste componente s√£o aqueles que fazem uso intensivo da rede.
    
-   **PC 2 representa a "Componente de Funcionalidade SMS"**. Aplicativos que enviam, recebem ou leem SMS ter√£o uma pontua√ß√£o alta neste componente. (Conectando com a an√°lise anterior, esta era uma caracter√≠stica chave para identificar malware).
    
-   **PC 3 pode ser visto como a "Componente de Identifica√ß√£o do Dispositivo"**, j√° que `READ_PHONE_STATE` permite o acesso a informa√ß√µes como o IMEI do telefone.
    
-   **PC 4 representa um "Componente de Gerenciamento de Contas/Credenciais"**, e sua carga negativa sugere um comportamento distinto para apps que usam essa permiss√£o.
    

Em suma, o gr√°fico "traduz" os componentes matem√°ticos abstratos (PC 1, PC 2, etc.) em comportamentos de aplicativos compreens√≠veis. Essa an√°lise √© extremamente √∫til para a engenharia de features e para a interpretabilidade de modelos de machine learning. Por exemplo, se um modelo de classifica√ß√£o identifica que PC 2 √© um forte preditor de malware, este mapa de calor nos diz explicitamente que a capacidade de **enviar SMS** √© a raz√£o por tr√°s dessa predi√ß√£o.

  

### 2.3 Distribui√ß√£o de Classes

![DATA_SPLIT](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/train_test_distribution.png)

  
**Explica√ß√£o**:
A figura abaixo apresenta a distribui√ß√£o das classes (_Benign_  e  _Malware_) nos conjuntos de treinamento e teste. A visualiza√ß√£o mostra o n√∫mero de amostras de cada classe em ambos os conjuntos, permitindo avaliar se a divis√£o foi balanceada e representativa.

- **Treinamento**:  
  - Benign: **5991**  
  - Malware: **3482**  
  - Total: **9473** amostras  

- **Teste**:  
  - Benign: **2534**  
  - Malware: **1526**  
  - Total: **4060** amostras  

**Propor√ß√£o (Benign:Malware)**: ~1.7:1 em ambos os conjuntos.  

**Principais Pontos**:  
‚úî Divis√£o estratificada (propor√ß√£o preservada).  
‚úî Conjunto de treinamento maior para aprendizado adequado.
    
Essa distribui√ß√£o √© crucial para garantir que o modelo seja treinado e avaliado em dados que refletem a propor√ß√£o real das classes, evitando vi√©s. 

  

## 3. üéØ Otimiza√ß√£o de Modelo

  

### 3.1 Import√¢ncia de Hiperpar√¢metros

![PARAM_IMPORTANCE](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/optuna_param_importance.png)

  

**Explica√ß√£o**:
O gr√°fico apresenta a import√¢ncia relativa dos hiperpar√¢metros no desempenho do modelo, conforme avaliado pelo framework Optuna. Os par√¢metros s√£o ordenados por sua influ√™ncia no valor objetivo, onde valores mais altos indicam maior impacto.

**Principais destaques:**

Os hiperpar√¢metros mais significativos s√£o:

-   **neighbors**  (import√¢ncia ~0.35) - o par√¢metro com maior influ√™ncia
    
-   **nav_depth**  (import√¢ncia ~0.25)
    
-   **leaf_size**  (import√¢ncia ~0.20)
    
-   **nples_split**  (import√¢ncia ~0.15)
    
-   **classifier**  (import√¢ncia ~0.10)
    

**Interpreta√ß√£o:**  
Os par√¢metros na extremidade direita do gr√°fico (com import√¢ncia acima de 0.10) merecem aten√ß√£o especial durante o ajuste fino do modelo, pois pequenas varia√ß√µes nestes podem impactar significativamente os resultados. Por outro lado, par√¢metros com import√¢ncia pr√≥xima de zero (como 'ic_params' e 'eaf_nodes') t√™m efeito m√≠nimo e podem ser mantidos com valores padr√£o para simplificar o processo de otimiza√ß√£o.
O gr√°fico de import√¢ncia dos hiperpar√¢metros fornece insights sobre quais par√¢metros do modelo exercem maior influ√™ncia no desempenho, permitindo reduzir o espa√ßo de busca e, consequentemente, tornar o processo de otimiza√ß√£o mais eficiente.


  

### 3.2 Curva de Otimiza√ß√£o

![OPTUNA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/optuna_optimization_history.png)

  

**Explica√ß√£o**:

O gr√°fico de hist√≥rico de otimiza√ß√£o documenta a evolu√ß√£o do desempenho do modelo ao longo de sucessivas tentativas de ajuste de hiperpar√¢metros, revelando importantes padr√µes:

**Trajet√≥ria de Melhoria**

-   O processo iniciou com um desempenho modesto (0.65), caracter√≠stico de configura√ß√µes n√£o otimizadas
    
-   Observa-se uma r√°pida ascens√£o na fase inicial (0.65 ‚Üí 0.80 em 5 tentativas), demonstrando a efic√°cia da abordagem de otimiza√ß√£o
    
-   A fase intermedi√°ria (tentativas 5-15) apresenta ganhos incrementais, t√≠pico de processos de refinamento
    
-   O plat√¥ alcan√ßado (0.90) ap√≥s 15 tentativas sugere a explora√ß√£o adequada do espa√ßo de par√¢metros
    

**Din√¢mica de Converg√™ncia**

1.  **Fase Explorat√≥ria**  (0-5 tentativas): Melhorias r√°pidas indicam que o algoritmo encontrou rapidamente regi√µes promissoras no espa√ßo de par√¢metros
    
2.  **Fase de Refinamento**  (5-15 tentativas): Aperfei√ßoamento gradual sugere ajustes finos nas combina√ß√µes de par√¢metros
    
3.  **Fase de Estabiliza√ß√£o**  (p√≥s-15 tentativas): Manuten√ß√£o do desempenho m√°ximo indica poss√≠vel esgotamento das melhorias vi√°veis
    

**Interpreta√ß√£o T√©cnica**

-   A diferen√ßa entre os valores inicial (0.65) e final (0.90) representa um ganho de ~38% no desempenho
    
-   A estabiliza√ß√£o precoce (em ~15 tentativas) pode sugerir:
    
    -   Efici√™ncia do algoritmo de otimiza√ß√£o
        
    -   Espa√ßo de par√¢metros bem definido
        
    -   Potencial para melhorias atrav√©s da expans√£o do espa√ßo de busca
        


Esta an√°lise demonstra a efetividade do processo de otimiza√ß√£o, com ganhos significativos de desempenho alcan√ßados de forma eficiente, ao mesmo tempo que aponta oportunidades para refinamentos adicionais.

  

### 3.2 Coordenadas Paralelas

![OPTUNA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/optuna_parallel_coordinate.png)

  

**Explica√ß√£o**:

O gr√°fico de coordenadas paralelas revela as rela√ß√µes entre m√∫ltiplos hiperpar√¢metros e o desempenho do modelo (0.89 a 0.97), destacando combina√ß√µes √≥timas atrav√©s de padr√µes vis√≠veis nas linhas superiores - alguns par√¢metros mostram forte correla√ß√£o com bons resultados (valores concentrados em faixas espec√≠ficas), enquanto outros apresentam varia√ß√£o aleat√≥ria, indicando menor influ√™ncia, sugerindo que a otimiza√ß√£o deve focar nos intervalos associados √†s melhores execu√ß√µes e reduzir a busca em par√¢metros menos impactantes.

  

## 4. üìà Avalia√ß√£o de Desempenho

  

### 4.1 Matriz de Confus√£o

![CONFMATRIX](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/confusion_matrix.png)

**Explica√ß√£o**:

A matriz de confus√£o demonstra a capacidade do modelo em distinguir entre amostras benignas e maliciosas. Das **2.534** amostras benignas reais, **2.457** foram corretamente classificadas, com apenas **77 falsos positivos**, o que demonstra **alta especificidade**.Das **1.526** amostras maliciosas, **1.355** foram corretamente identificadas, com **171 falsos negativos**, revelando uma **boa sensibilidade**, embora ainda haja espa√ßo para melhorias na detec√ß√£o de amea√ßas. O desempenho indica que o modelo apresenta **baixo √≠ndice de alarmes falsos** e uma **efic√°cia significativa na identifica√ß√£o de malwares**, sendo adequado para cen√°rios que exigem confian√ßa tanto na detec√ß√£o quanto na minimiza√ß√£o de alertas indevidos.

### 4.2 Curvas de Avalia√ß√£o AUC-ROC

![ROC](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/roc_curve.png)

**Explica√ß√£o**:

A curva ROC (Receiver Operating Characteristic) compara a taxa de verdadeiros positivos (sensibilidade) com a taxa de falsos positivos, em diferentes limiares de decis√£o. A √°rea sob a curva (AUC) indica a capacidade do modelo de distinguir entre as classes. Um valor de AUC pr√≥ximo de 1, como o obtido (0.982), demonstra excelente desempenho discriminativo, com m√≠nima sobreposi√ß√£o entre classes benignas e maliciosas.

### 4.3 Curvas de Avalia√ß√£o Precis√£o e Recall

![PR](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/precision_recall_curve.png)

  

**Explica√ß√£o**:

A curva de Precis√£o-Recall √© particularmente √∫til em cen√°rios com classes desbalanceadas. Ela ilustra a rela√ß√£o entre a **precis√£o** (propor√ß√£o de verdadeiros positivos entre os positivos previstos) e o **recall** (propor√ß√£o de verdadeiros positivos identificados corretamente). O valor m√©dio de precis√£o (Average Precision = 0.975) indica que, mesmo com alto recall, o modelo mant√©m uma elevada taxa de precis√£o, minimizando alarmes falsos.

  

### 4.4 Avalia√ß√£o Por Classe

![PR](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/metrics_by_class.png)

  

**Explica√ß√£o**:

Este gr√°fico compara as m√©tricas de avalia√ß√£o ‚Äî **Precis√£o**, **Recall** e **F1-Score** ‚Äî para cada classe (Benigno e Malware), permitindo uma an√°lise detalhada do equil√≠brio do modelo entre diferentes tipos de erro.

  

-  **Benigno**: apresenta alta **revoca√ß√£o (0.970)**, o que indica que quase todos os aplicativos benignos foram corretamente identificados. A **precis√£o (0.935)** tamb√©m √© elevada, significando que a maioria das previs√µes como benignas realmente corresponde a essa classe. O **F1-Score (0.952)** resume esse bom equil√≠brio entre precis√£o e recall.

-  **Malware**: tem uma **precis√£o ainda mais alta (0.946)**, o que √© crucial em sistemas de seguran√ßa, pois minimiza o n√∫mero de falsos positivos (benignos classificados como malware). A **revoca√ß√£o (0.888)**, embora ligeiramente inferior, ainda indica boa capacidade de detec√ß√£o. O **F1-Score (0.916)** demonstra um desempenho s√≥lido e consistente na identifica√ß√£o de amea√ßas.

  

Em conjunto, esses resultados sugerem que o modelo mant√©m **bom equil√≠brio entre seguran√ßa (detec√ß√£o de malware) e confiabilidade (baixo alarme falso)**, sendo apropriado para ambientes onde a minimiza√ß√£o de riscos e ru√≠do operacional √© essencial.

  

### 4.4 Avalia√ß√£o Por Classe

![PR](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/probability_distribution.png)

  

**Explica√ß√£o**:

Este gr√°fico exibe a densidade das probabilidades preditas pelo modelo para cada classe (Benigno em azul, Malware em vermelho), com um **limiar de decis√£o fixado em 0.5** (linha tracejada).

  

Observa√ß√µes importantes:

  

- A maioria dos exemplos **benignos** concentra-se √† esquerda do limiar (probabilidades pr√≥ximas de 0), indicando alta confian√ßa do modelo ao classific√°-los corretamente como n√£o maliciosos.

- De forma an√°loga, a maioria dos exemplos **maliciosos** se agrupa √† direita do limiar (probabilidades pr√≥ximas de 1), evidenciando tamb√©m alta confian√ßa na classifica√ß√£o como malware.

- A separa√ß√£o clara entre as duas distribui√ß√µes sugere **alta discriminabilidade** do modelo, ou seja, baixa ambiguidade na predi√ß√£o.

- A baixa sobreposi√ß√£o entre as curvas reduz a taxa de erros de classifica√ß√£o, como falsos positivos e falsos negativos.

  

Esse comportamento √© desej√°vel em sistemas de detec√ß√£o, pois refor√ßa que o modelo n√£o apenas acerta as classes, mas o faz com **alta confian√ßa estat√≠stica**, tornando a ferramenta confi√°vel para uso em ambientes cr√≠ticos.

  

## 5. üîç Interpretabilidade

  

### 5.1 An√°lise SHAP Summary Plot

![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/shap_summary_plot_LGBMClassifier_20250701_211240.png)

  

**Explica√ß√£o**:

Este gr√°fico resume a **influ√™ncia de cada permiss√£o Android** sobre as previs√µes do modelo, utilizando valores SHAP, que quantificam o impacto de cada feature na sa√≠da do classificador.

  

**Interpreta√ß√£o do Gr√°fico:**

  

- O eixo X representa o valor SHAP, ou seja, o **impacto individual** da feature na predi√ß√£o. Valores positivos empurram a previs√£o para ‚Äúmalware‚Äù, enquanto valores negativos favorecem a classe ‚Äúbenigno‚Äù.

- Cada ponto representa uma amostra; a cor indica o valor da feature (vermelho = valor alto / presente, azul = valor baixo / ausente).

- As permiss√µes mais relevantes incluem:

-  `SEND_SMS_1.0`, `READ_PHONE_STATE_1.0`, `READ_SMS_1.0`: quando **ativas (vermelhas)**, t√™m forte impacto positivo na classifica√ß√£o como **malware**, sugerindo comportamento malicioso.

-  `GET_ACCOUNTS_1.0` e `ACCESS_NETWORK_STATE_1.0`: apresentam impacto misto, com comportamentos diferentes dependendo do contexto.

- Permiss√µes como `RECEIVE_BOOT_COMPLETED_1.0` e `WRITE_HISTORY_BOOKMARKS_1.0` tamb√©m contribuem, mas com menor intensidade.

  

Este gr√°fico permite concluir que o modelo **aprende padr√µes interpret√°veis** e condizentes com pr√°ticas conhecidas de malware, refor√ßando a confiabilidade e **explicabilidade** do processo de decis√£o. Al√©m disso, evidencia a import√¢ncia de um subconjunto reduzido de permiss√µes, o que pode auxiliar na **redu√ß√£o dimensional** e auditoria dos atributos usados.

  

### 5.2 An√°lise SHAP Force Plot

![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/shap_force_plot.png)

  

**Explica√ß√£o**:

Este gr√°fico visualiza como os valores das features influenciaram uma predi√ß√£o espec√≠fica do modelo. A previs√£o final (`f(x) = 5.94`) resulta da soma do valor base (m√©dia das predi√ß√µes) com os impactos acumulados de cada atributo.

  

**Interpreta√ß√£o:**

  

-  **Base value**: √© o valor m√©dio da sa√≠da do modelo sem considerar nenhuma feature (refer√™ncia neutra).

-  **Setas vermelhas (‚Üí higher)**: indicam features que **aumentaram** a probabilidade da amostra ser classificada como **malware**.

-  `SEND_SMS_1.0`, `ACCESS_NETWORK_STATE_1.0` e `GET_ACCOUNTS_1.0` contribu√≠ram positivamente, impulsionando a predi√ß√£o para a classe maliciosa.

-  **Seta azul (‚Üí lower)**: representa uma feature que **reduziu** essa probabilidade.

-  `WRITE_HISTORY_BOOKMARKS_1.0` teve um impacto negativo, atuando como um fator benigno.

  

O valor final de **5.94** est√° bem acima do limiar de decis√£o, refor√ßando que o modelo classificou esta inst√¢ncia com **alta confian√ßa como malware**.

  

### 5.3 An√°lise import√¢ncia das caracter√≠sticas LIME

![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/lime_feature_importance_20250701_232317.png)

  

**Explica√ß√£o**:

O gr√°fico apresenta a contribui√ß√£o individual de cada feature na decis√£o do modelo para uma **amostra espec√≠fica**, permitindo uma an√°lise **local** da explica√ß√£o. Os pesos indicam o quanto cada atributo influenciou a classifica√ß√£o:

  

-  **Barras azuis (positivas)**: caracter√≠sticas que **favoreceram a predi√ß√£o como malware**.

- Destaques:

-  `SEND_SMS > -0.56` (peso: +0.242)

-  `READ_PHONE_STATE > 0.76` (peso: +0.241)

-  `INTERNET > 0.38` (peso: +0.241)

‚Üí A presen√ßa ou valores altos dessas permiss√µes aumentaram significativamente a probabilidade de a amostra ser classificada como maliciosa.

-  **Barras vermelhas (negativas)**: caracter√≠sticas que **atuaram contra a classifica√ß√£o como malware**, ou seja, aproximaram a inst√¢ncia da classe benigna.

- Destaques:

-  `WRITE_HISTORY_BOOKMARKS <= -0.22` (peso: ‚Äì0.224)

-  `GET_ACCOUNTS <= 1.53` (peso: ‚Äì0.188)

-  `READ_SMS <= -0.48` (peso: ‚Äì0.119)

‚Üí Esses atributos, ao estarem ausentes ou abaixo de determinado valor, indicaram comportamento benigno ao modelo.

  

Este gr√°fico complementa a explica√ß√£o global do SHAP ao mostrar **como o modelo tomou uma decis√£o em um caso concreto**, oferecendo uma forma interpret√°vel e confi√°vel de justificar decis√µes individuais ‚Äî fundamental em contextos como ciberseguran√ßa e auditoria.

  

### 5.4 An√°lise Probabilidade de Predi√ß√£o LIME

![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/lime_interpretability.png)

  

**Insights**:

O gr√°fico mostra como as **features ativas** (valores fornecidos √† direita) impactaram a predi√ß√£o do modelo (barra central), contribuindo para a classifica√ß√£o como **malware (classe 1)** ou **benigno (classe 0)**.

  

#### üî∂ Principais contribui√ß√µes para **classe 1 (malware)**:

  

-  `READ_PHONE_STATE = 0.76`

-  `INTERNET = 0.39`

-  `SEND_SMS = 1.78`

-  `CHANGE_WIFI_MULTICAST_STATE = -0.12`

  

Estas permiss√µes s√£o **fortes indicativos de comportamento malicioso** e empurraram a predi√ß√£o para a classe ‚Äúmalware‚Äù.

  

#### üî∑ Principais contribui√ß√µes para **classe 0 (benigno)**:

  

-  `WRITE_HISTORY_BOOKMARKS = -0.30`

-  `GET_ACCOUNTS = -0.64`

-  `READ_CALL_LOG = -0.12`

-  `USE_CREDENTIALS = -0.33`

-  `READ_SMS = -0.48`

-  `MASTER_CLEAR = -0.11`

  

Essas permiss√µes, por estarem ausentes ou com valor baixo, puxaram a predi√ß√£o em dire√ß√£o √† classe benigna. Mesmo assim, o modelo atribuiu **alta probabilidade (‚âà 1.00)** para a classe malware, dado o maior peso das permiss√µes maliciosas.

### 5.4 An√°lise da √Årvore de Decis√£o

![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/decision_tree_plot_ExtraTreesClassifier_20250701_232317.png)
  A imagem exibe a estrutura de uma √∫nica **√°rvore de decis√£o**, que √© a primeira √°rvore de um modelo de `ExtraTreesClassifier`. Este tipo de modelo de machine learning cria uma "floresta" de m√∫ltiplas √°rvores e combina seus resultados, mas a visualiza√ß√£o de uma √∫nica √°rvore nos permite entender a l√≥gica de classifica√ß√£o que o modelo aprendeu.

A √°rvore funciona como um fluxograma de decis√µes:

-   **N√≥s (caixas):** Cada n√≥ interno representa uma pergunta sobre uma feature espec√≠fica (uma permiss√£o do Android).
    
-   **Ramos (setas):** As setas indicam o caminho a seguir com base na resposta ("sim" ou "n√£o", ou, mais precisamente, `True` ou `False` para a condi√ß√£o).
    
-   **Folhas (n√≥s finais):** Os n√≥s na base da √°rvore representam a decis√£o final de classifica√ß√£o.
    

Dentro de cada n√≥, temos as seguintes informa√ß√µes:

-   **Condi√ß√£o de divis√£o:** A regra usada para dividir os dados (ex: `SEND_SMS_1.0 <= 0.852`).
    
-   **`entropy`:** Uma medida de impureza do n√≥. Um valor de 0 significa que o n√≥ √© "puro" (todas as amostras pertencem √† mesma classe).
    
-   **`samples`:** O n√∫mero de aplicativos que chegaram a este n√≥.
    
-   **`value`:** A distribui√ß√£o das classes neste n√≥ (ex: `[5991, 3482]` significa 5991 amostras da classe 0 e 3482 da classe 1).
    
-   **`class`:** A classe majorit√°ria no n√≥. A cor do n√≥ (laranja para classe 0 - Benigno, azul para classe 1 - Malware) reflete essa maioria.
    

**Principais destaques:**

A an√°lise da estrutura da √°rvore revela uma clara hierarquia na import√¢ncia das permiss√µes para a detec√ß√£o de malware.

-   **Feature Mais Importante:** A primeira decis√£o, no topo da √°rvore (n√≥ raiz), √© baseada na permiss√£o `SEND_SMS_1.0`. Isso significa que, de todas as permiss√µes dispon√≠veis, esta √© a que melhor consegue separar os aplicativos benignos dos maliciosos no primeiro passo.
    
-   **Caminho Cr√≠tico para Malware:** O caminho √† direita, onde `SEND_SMS_1.0` √© `True` (maior que 0.852), leva a um n√≥ que √© predominantemente **Malware (azul)**, com 1890 amostras de malware contra 343 benignas. Isso indica que a solicita√ß√£o da permiss√£o para enviar SMS √© um fort√≠ssimo indicador de mal√≠cia.
    
-   **Hierarquia de Permiss√µes:** Para os aplicativos que _n√£o_ solicitam `SEND_SMS` (o caminho da esquerda), a pr√≥xima pergunta mais importante √© sobre a permiss√£o `READ_PHONE_STATE_1.0`. Se a resposta for sim, a suspeita aumenta. Se for n√£o, o modelo continua a perguntar sobre outras permiss√µes como `GET_ACCOUNTS_1.0`.
    
-   **Pureza das Folhas:** O objetivo da √°rvore √© terminar em folhas que sejam o mais "puras" poss√≠vel (predominantemente de uma √∫nica cor). Vemos que a √°rvore consegue isolar grupos de malware (folhas azuis) e de aplicativos benignos (folhas laranjas) com razo√°vel sucesso.
    

**Interpreta√ß√£o:**

Esta √°rvore de decis√£o torna o processo de classifica√ß√£o do modelo transparente e interpret√°vel. Ela essencialmente cria um conjunto de regras "se-ent√£o" para identificar malware.

A l√≥gica do modelo pode ser lida como um processo de triagem:

1.  **Primeiro, verifique se o aplicativo envia SMS.** Se sim, a probabilidade de ser malware √© muito alta.
    
2.  **Se n√£o, verifique se ele l√™ o estado do telefone.** Esta √© a segunda bandeira vermelha mais importante.
    
3.  **Se n√£o, verifique se ele acessa as contas do usu√°rio.** E assim por diante.
    

As permiss√µes que aparecem nos n√≠veis superiores da √°rvore (`SEND_SMS`, `READ_PHONE_STATE`, `GET_ACCOUNTS`) s√£o as mais impactantes para o modelo. Esta conclus√£o est√° perfeitamente alinhada com as an√°lises de PCA anteriores, que tamb√©m destacaram a import√¢ncia dessas mesmas features. A √°rvore, no entanto, nos d√° uma vis√£o mais direta e processual, mostrando a ordem e a l√≥gica exata das decis√µes que levam a uma classifica√ß√£o final de **Benigno** ou **Malware**.

## 6. Performance geral do Pipeline

  

### 5.2 Desempenho Tempo x RAM

![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/performance_metrics.jpg)

  


A imagem apresentada √© um gr√°fico de barras e linhas que detalha as m√©tricas de performance (tempo de execu√ß√£o em segundos e consumo de mem√≥ria RAM em MB) para cada etapa de um pipeline de Machine Learning (ML).

**An√°lise do Gr√°fico:**

O gr√°fico possui dois eixos Y:

-   **Eixo Y Esquerdo (Azul):** Representa o "Elapsed Time (seconds)" (Tempo Decorrido em segundos) para cada etapa. As barras azuis mostram esses valores.
    
-   **Eixo Y Direito (Verde):** Representa o "Memory Usage (MB)" (Uso de Mem√≥ria em MB). A linha verde com marcadores circulares mostra esses valores.
    

As etapas do pipeline de ML est√£o no **Eixo X**, rotuladas como "Step Name":

1.  **Data Info**
    
2.  **Preprocessing**
    
3.  **Feature Engineering**
    
4.  **Hyperparameter**
    
5.  **Interpretability**
    
6.  **Evaluation**
    

Vamos analisar cada etapa:

-   **Data Info:**
    
    -   **Tempo de Execu√ß√£o:** 5.57 segundos (barra azul)
        
    -   **Uso de Mem√≥ria:** 4.99 MB (marcador verde)
        
    -   Esta etapa inicial para obter informa√ß√µes sobre os dados √© relativamente r√°pida e consome pouca mem√≥ria.
        
-   **Preprocessing (Pr√©-processamento):**
    
    -   **Tempo de Execu√ß√£o:** 4.50 segundos (barra azul)
        
    -   **Uso de Mem√≥ria:** 98.17 MB (marcador verde)
        
    -   Embora o tempo de execu√ß√£o seja menor que o de "Data Info", o consumo de mem√≥ria aumenta significativamente, o que √© comum em etapas de limpeza, tratamento de valores ausentes ou normaliza√ß√£o de dados.
        
-   **Feature Eng (Engenharia de Caracter√≠sticas):**
    
    -   **Tempo de Execu√ß√£o:** 0.92 segundos (barra azul)
        
    -   **Uso de Mem√≥ria:** 23.74 MB (marcador verde)
        
    -   Esta √© a etapa mais r√°pida em termos de tempo de execu√ß√£o e possui um consumo de mem√≥ria moderado. A cria√ß√£o ou transforma√ß√£o de caracter√≠sticas pode ser eficiente em alguns casos.
        
-   **Hyperparameter (Otimiza√ß√£o de Hiperpar√¢metros):**
    
    -   **Tempo de Execu√ß√£o:** 38.95 segundos (barra azul)
        
    -   **Uso de Mem√≥ria:** 39.57 MB (marcador verde)
        
    -   Esta √© a etapa mais demorada do pipeline, consumindo quase 39 segundos. Isso √© esperado, pois a otimiza√ß√£o de hiperpar√¢metros (por exemplo, busca em grade, busca aleat√≥ria) envolve a treinamento e avalia√ß√£o de m√∫ltiplos modelos. O consumo de mem√≥ria √© relativamente baixo em compara√ß√£o com o pr√©-processamento.
        
-   **Interpretability (Interpretabilidade):**
    
    -   **Tempo de Execu√ß√£o:** 4.51 segundos (barra azul)
        
    -   **Uso de Mem√≥ria:** 354.16 MB (marcador verde)
        
    -   Embora o tempo de execu√ß√£o seja razo√°vel, esta etapa apresenta o **maior consumo de mem√≥ria RAM** de todo o pipeline, atingindo mais de 354 MB. Isso pode indicar o uso de algoritmos complexos para explicar as previs√µes do modelo, que podem exigir a manipula√ß√£o de grandes estruturas de dados.
        
-   **Evaluation (Avalia√ß√£o):**
    
    -   **Tempo de Execu√ß√£o:** 8.19 segundos (barra azul)
        
    -   **Uso de Mem√≥ria:** 138.94 MB (marcador verde)
        
    -   A etapa final, respons√°vel por avaliar o desempenho do modelo, leva um tempo consider√°vel e tem um consumo de mem√≥ria elevado, embora menor que a etapa de interpretabilidade. Isso pode envolver o c√°lculo de diversas m√©tricas e a gera√ß√£o de relat√≥rios.
        

**Pontos Chave e Insights:**

-   **Gargalo de Tempo:** A etapa de "Hyperparameter" √© o principal gargalo em termos de tempo de execu√ß√£o.
    
-   **Gargalo de Mem√≥ria:** A etapa de "Interpretability" √© o principal gargalo em termos de consumo de mem√≥ria RAM.
    
-   **Trade-offs:** √â interessante observar que as etapas mais demoradas nem sempre s√£o as que mais consomem mem√≥ria, e vice-versa. Por exemplo, "Hyperparameter" √© lenta mas n√£o √© a que mais usa mem√≥ria, enquanto "Interpretability" consome muita mem√≥ria em um tempo moderado.
    
-   **Otimiza√ß√£o:** Este tipo de gr√°fico √© crucial para identificar √°reas onde a otimiza√ß√£o pode ser mais eficaz. Por exemplo, se a mem√≥ria for um problema, focar em reduzir o consumo na etapa de "Interpretability" seria priorit√°rio. Se o tempo for cr√≠tico, otimizar a "Hyperparameter" seria essencial.
    

Em resumo, a imagem fornece uma vis√£o clara e quantitativa do desempenho de cada componente do pipeline de ML, permitindo que os desenvolvedores e engenheiros de ML identifiquem e abordem inefici√™ncias em termos de tempo e uso de recursos.

  

## 7. üìù Considera√ß√µes Finais

O pipeline de Machine Learning "MH-AutoML" demonstra uma robustez not√°vel na detec√ß√£o de malwares em aplica√ß√µes Android, com base nas permiss√µes solicitadas. A an√°lise detalhada dos artefatos gerados em cada etapa oferece insights valiosos sobre o comportamento do modelo e a import√¢ncia das caracter√≠sticas.

**Pontos Fortes do Pipeline:**

-   **Alta Performance:** As m√©tricas de avalia√ß√£o, como AUC (0.992 ¬±0.03) e F1-Score Balanceado (0.968), indicam um desempenho excepcional na classifica√ß√£o, minimizando tanto falsos positivos quanto falsos negativos. A matriz de confus√£o e as curvas ROC/Precision-Recall corroboram a capacidade discriminativa do modelo.
    
-   **Interpretabilidade Aprofundada:** O uso de ferramentas como SHAP e LIME √© crucial. O SHAP Summary Plot e o Force Plot revelam que permiss√µes como `SEND_SMS`, `READ_PHONE_STATE` e `INTERNET` s√£o os principais indicadores de comportamento malicioso, o que √© consistente com as expectativas de seguran√ßa de aplicativos. A an√°lise LIME complementa, fornecendo explica√ß√µes localizadas para decis√µes espec√≠ficas, essencial para a confian√ßa em cen√°rios cr√≠ticos como ciberseguran√ßa. A visualiza√ß√£o da √°rvore de decis√£o de `ExtraTreesClassifier` tamb√©m oferece uma interpreta√ß√£o clara das regras de classifica√ß√£o aprendidas pelo modelo.
    
-   **Engenharia de Features Eficiente:** As etapas de sele√ß√£o de caracter√≠sticas (LASSO e ANOVA) e redu√ß√£o de dimensionalidade (PCA) foram bem aplicadas. O biplot do PCA demonstrou uma separa√ß√£o clara entre as classes benignas e maliciosas, refor√ßando que as permiss√µes s√£o caracter√≠sticas discriminativas. O heatmap das componentes principais "traduz" essas componentes em padr√µes de comportamento de aplicativos, como "Acesso √† Internet" (PC 1) e "Funcionalidade SMS" (PC 2).
    
-   **Otimiza√ß√£o de Hiperpar√¢metros Eficaz:** O processo de otimiza√ß√£o de hiperpar√¢metros, utilizando Optuna, demonstrou efici√™ncia ao alcan√ßar um plat√¥ de desempenho elevado em poucas tentativas. A an√°lise de import√¢ncia dos hiperpar√¢metros ("neighbors", "nav_depth", "leaf_size", "nples_split" e "classifier") direciona o ajuste fino, e as coordenadas paralelas mostram as combina√ß√µes que levam aos melhores resultados.
    
-   **Gest√£o de Dados:** A an√°lise de valores faltantes e a distribui√ß√£o de classes nos conjuntos de treinamento e teste (`~1.7:1` Benigno:Malware) indicam uma prepara√ß√£o de dados cuidadosa, com divis√£o estratificada para evitar vieses.
    

**Desafios e Oportunidades de Otimiza√ß√£o:**

-   **Gargalo de Mem√≥ria na Interpretabilidade:** Conforme a an√°lise de desempenho do pipeline, a etapa de "Interpretability" consome a maior quantidade de mem√≥ria RAM (354.16 MB). Embora seja fundamental para a explicabilidade, otimiza√ß√µes nesta fase (e.g., amostragem, t√©cnicas mais eficientes) podem ser exploradas para reduzir o consumo de recursos, especialmente em ambientes com restri√ß√£o de mem√≥ria.
    
-   **Tempo de Execu√ß√£o na Otimiza√ß√£o de Hiperpar√¢metros:** A etapa de "Hyperparameter" √© a mais demorada (38.95 segundos). Para grandes conjuntos de dados ou otimiza√ß√µes mais extensas, m√©todos como otimiza√ß√£o bayesiana mais avan√ßada ou a paraleliza√ß√£o da busca podem ser considerados para acelerar o processo.
    
    

Em suma, o MH-AutoML apresenta um framework robusto e bem-sucedido para a detec√ß√£o de malware, com um equil√≠brio not√°vel entre alta performance preditiva e transpar√™ncia em suas decis√µes. As considera√ß√µes sobre o consumo de recursos indicam √°reas potenciais para otimiza√ß√£o cont√≠nua, garantindo que o pipeline n√£o apenas seja eficaz, mas tamb√©m eficiente em sua execu√ß√£o.