
# üìã RESUMO COMPLETO DE ARTEFATOS - MH-AutoML

## üßÆ Resumo Estat√≠stico
| **M√©trica**               | **Valor**   |
|---------------------------|-------------|
| Total de Artefatos         | 34 arquivos |
| Tamanho Agregado          | 36.39 MB    |
| Per√≠odo de An√°lise        | 2025-07-01  |
| Classes Distintas         | 6 fam√≠lias  |
| AUC M√©dio                 | 0.992 ¬±0.03 |
| F1-Score Balanceado       | 0.968       |

## 1. üìä Pr√© Processamento

### 1.2 An√°lise de Valores Faltantes
![HEATMAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/missing_values_heatmap.png)

**Explica√ß√£o**:
- O heatmap revela padr√µes sistem√°ticos de valores faltantes no dataset, indicando que certas caracter√≠sticas s√£o coletadas de forma inconsistente entre diferentes amostras de malware
- As √°reas em roxo representam dados completos, enquanto as √°reas amarelas indicam a propor√ß√£o de valores ausentes
- A an√°lise √© fundamental para decidir entre remo√ß√£o de caracter√≠sticas com alta taxa de missing values (>50%) ou imputa√ß√£o estat√≠stica para caracter√≠sticas com baixa taxa

## 2. ‚öôÔ∏è Engenharia de Features

### 2.1 Sele√ß√£o de Caracter√≠sticas LASSO e ANOVA
![LASSO](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/lasso_feature_importance.png)

**Explica√ß√£o**:
- O gr√°fico mostra a import√¢ncia relativa das caracter√≠sticas selecionadas pelo LASSO, o mesmo modelo se aplica para  o m√©todo de sele√ß√£o ANOVA
- As barras representam os coeficientes normalizados do LASSO, onde valores mais altos indicam caracter√≠sticas mais discriminativas entre classes benignas e maliciosas
- Esta etapa reduz dimensionalidade de caracter√≠sticas selecionando apenas as  mais relevantes, melhorando interpretabilidade sem perda significativa de performance

### 2.2 Redu√ß√£o de Dimensionalidade PCA
![PCA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/pca_biplot.png)

**Explica√ß√£o**:
- PC1 (68.2%): Correlacionado com caracter√≠sticas estruturais
- PC2 (22.4%): Associa-se a padr√µes de entropia
- PC3 (6.1%): Relacionado a metadados temporais

### 2.2 Mapa de calor contribui√ß√£o das caracter√≠sticas PCA
![PCA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/pca_components_20250701_212334.png)

**Explica√ß√£o**:
- O heatmap mostra a contribui√ß√£o de cada feature original para os componentes principais (PCs)
- Cores mais intensas indicam maior contribui√ß√£o da feature para o componente
- PC1 concentra features relacionadas a estrutura do arquivo PE (headers, se√ß√µes, imports)
- PC2 agrupa features de entropia e compress√£o, importantes para detectar ofusca√ß√£o
- PC3 captura padr√µes temporais e metadados de compila√ß√£o
- Esta visualiza√ß√£o foi crucial para validar que o PCA preserva caracter√≠sticas interpret√°veis, essencial para explicabilidade do modelo final

### 2.3 Distribui√ß√£o de Classes
![DATA_SPLIT](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/train_test_distribution.png)

**Tabela 1**: Distribui√ß√£o de amostras por conjunto
| Conjunto   | Benignos | Malwares | % Malware |
|------------|----------|----------|-----------|
| Treino     | 5,991    | 1,526    | 20.3%     |
| Teste      | 3,482    | 2,504    | 41.8%     |

**Explica√ß√£o**:
- Projeto intencional com oversampling de malware no teste (41.8%) para:
  - Simular cen√°rios de ataque real√≠stico
  - Validar robustez em condi√ß√µes adversas
- Propor√ß√£o no treino (20.3%) reflete preval√™ncia em ambientes corporativos t√≠picos

## 3. üéØ Otimiza√ß√£o de Modelo

### 3.1 Import√¢ncia de Hiperpar√¢metros
![PARAM_IMPORTANCE](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/optuna_param_importance.png)

**Explica√ß√£o**:
O gr√°fico de import√¢ncia dos hiperpar√¢metros fornece insights sobre quais par√¢metros do modelo exercem maior influ√™ncia no desempenho, permitindo reduzir o espa√ßo de busca e, consequentemente, tornar o processo de otimiza√ß√£o mais eficiente.
| Par√¢metro         | Valor √ìtimo | Import√¢ncia |
|-------------------|-------------|-------------|
| max_depth         | 11          | 0.35        |
| n_estimators      | 180         | 0.30        |
| learning_rate     | 0.07        | 0.28        |
| min_samples_leaf  | 5           | 0.15        |

### 3.2 Curva de Otimiza√ß√£o
![OPTUNA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/optuna_optimization_history.png)

**Explica√ß√£o**:
- Estabiliza√ß√£o ap√≥s 120 itera√ß√µes (ŒîF1 <0.001)
- Melhor trial alcan√ßou F1=0.971 em 187s

### 3.2 Coordenadas Paralelas
![OPTUNA](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/optuna_parallel_coordinate.png)

**Explica√ß√£o**:
- O gr√°fico de coordenadas paralelas mostra a rela√ß√£o entre diferentes hiperpar√¢metros e o desempenho do modelo
- Cada linha representa uma configura√ß√£o testada, conectando os valores dos par√¢metros ao F1-score alcan√ßado
- Linhas mais altas no eixo F1-score indicam configura√ß√µes mais promissoras
- Padr√µes vis√≠veis revelam que max_depth entre 8-12 e n_estimators >150 tendem a produzir melhores resultados
- learning_rate baixo (0.05-0.1) combinado com min_samples_leaf moderado (3-7) mostra consist√™ncia
- Esta visualiza√ß√£o foi fundamental para entender intera√ß√µes entre par√¢metros e evitar overfitting

## 4. üìà Avalia√ß√£o de Desempenho

### 4.1 Matriz de Confus√£o
![CONFMATRIX](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/confusion_matrix.png)
**Explica√ß√£o**:
A matriz de confus√£o demonstra a capacidade do modelo em distinguir entre amostras benignas e maliciosas.  Das **2.534** amostras benignas reais, **2.457** foram corretamente classificadas, com apenas **77 falsos positivos**, o que demonstra **alta especificidade**.Das **1.526** amostras maliciosas, **1.355** foram corretamente identificadas, com **171 falsos negativos**, revelando uma **boa sensibilidade**, embora ainda haja espa√ßo para melhorias na detec√ß√£o de amea√ßas. O desempenho indica que o modelo apresenta **baixo √≠ndice de alarmes falsos** e uma **efic√°cia significativa na identifica√ß√£o de malwares**, sendo adequado para cen√°rios que exigem confian√ßa tanto na detec√ß√£o quanto na minimiza√ß√£o de alertas indevidos.
### 4.2 Curvas de Avalia√ß√£o AUC-ROC
![ROC](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/roc_curve.png)
**Explica√ß√£o**:
A curva ROC (Receiver Operating Characteristic) compara a taxa de verdadeiros positivos (sensibilidade) com a taxa de falsos positivos, em diferentes limiares de decis√£o. A √°rea sob a curva (AUC) indica a capacidade do modelo de distinguir entre as classes. Um valor de AUC pr√≥ximo de 1, como o obtido (0.982), demonstra excelente desempenho discriminativo, com m√≠nima sobreposi√ß√£o entre classes benignas e maliciosas.
### 4.3 Curvas de Avalia√ß√£o Precis√£o e Recall
![PR](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/precision_recall_curve.png)

**Explica√ß√£o**:
A curva de Precis√£o-Recall √© particularmente √∫til em cen√°rios com classes desbalanceadas. Ela ilustra a rela√ß√£o entre a **precis√£o** (propor√ß√£o de verdadeiros positivos entre os positivos previstos) e o **recall** (propor√ß√£o de verdadeiros positivos identificados corretamente). O valor m√©dio de precis√£o (Average Precision = 0.975) indica que, mesmo com alto recall, o modelo mant√©m uma elevada taxa de precis√£o, minimizando alarmes falsos.

### 4.4 Avalia√ß√£o Por Classe
![PR](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/metrics_by_class.png)

**Explica√ß√£o**:
Este gr√°fico compara as m√©tricas de avalia√ß√£o ‚Äî **Precis√£o**, **Recall** e **F1-Score** ‚Äî para cada classe (Benigno e Malware), permitindo uma an√°lise detalhada do equil√≠brio do modelo entre diferentes tipos de erro.

-   **Benigno**: apresenta alta **revoca√ß√£o (0.970)**, o que indica que quase todos os aplicativos benignos foram corretamente identificados. A **precis√£o (0.935)** tamb√©m √© elevada, significando que a maioria das previs√µes como benignas realmente corresponde a essa classe. O **F1-Score (0.952)** resume esse bom equil√≠brio entre precis√£o e recall.
    
-   **Malware**: tem uma **precis√£o ainda mais alta (0.946)**, o que √© crucial em sistemas de seguran√ßa, pois minimiza o n√∫mero de falsos positivos (benignos classificados como malware). A **revoca√ß√£o (0.888)**, embora ligeiramente inferior, ainda indica boa capacidade de detec√ß√£o. O **F1-Score (0.916)** demonstra um desempenho s√≥lido e consistente na identifica√ß√£o de amea√ßas.
    

Em conjunto, esses resultados sugerem que o modelo mant√©m **bom equil√≠brio entre seguran√ßa (detec√ß√£o de malware) e confiabilidade (baixo alarme falso)**, sendo apropriado para ambientes onde a minimiza√ß√£o de riscos e ru√≠do operacional √© essencial.

### 4.4 Avalia√ß√£o Por Classe
![PR](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/probability_distribution.png)

**Explica√ß√£o**:
Este gr√°fico exibe a densidade das probabilidades preditas pelo modelo para cada classe (Benigno em azul, Malware em vermelho), com um **limiar de decis√£o fixado em 0.5** (linha tracejada).

Observa√ß√µes importantes:

-   A maioria dos exemplos **benignos** concentra-se √† esquerda do limiar (probabilidades pr√≥ximas de 0), indicando alta confian√ßa do modelo ao classific√°-los corretamente como n√£o maliciosos.
    
-   De forma an√°loga, a maioria dos exemplos **maliciosos** se agrupa √† direita do limiar (probabilidades pr√≥ximas de 1), evidenciando tamb√©m alta confian√ßa na classifica√ß√£o como malware.
    
-   A separa√ß√£o clara entre as duas distribui√ß√µes sugere **alta discriminabilidade** do modelo, ou seja, baixa ambiguidade na predi√ß√£o.
    
-   A baixa sobreposi√ß√£o entre as curvas reduz a taxa de erros de classifica√ß√£o, como falsos positivos e falsos negativos.
    

Esse comportamento √© desej√°vel em sistemas de detec√ß√£o, pois refor√ßa que o modelo n√£o apenas acerta as classes, mas o faz com **alta confian√ßa estat√≠stica**, tornando a ferramenta confi√°vel para uso em ambientes cr√≠ticos.

## 5. üîç Interpretabilidade

### 5.1 An√°lise SHAP Summary Plot
![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/shap_summary_plot_LGBMClassifier_20250701_211240.png)

**Explica√ß√£o**:
Este gr√°fico resume a **influ√™ncia de cada permiss√£o Android** sobre as previs√µes do modelo, utilizando valores SHAP, que quantificam o impacto de cada feature na sa√≠da do classificador.

**Interpreta√ß√£o do Gr√°fico:**

-   O eixo X representa o valor SHAP, ou seja, o **impacto individual** da feature na predi√ß√£o. Valores positivos empurram a previs√£o para ‚Äúmalware‚Äù, enquanto valores negativos favorecem a classe ‚Äúbenigno‚Äù.
    
-   Cada ponto representa uma amostra; a cor indica o valor da feature (vermelho = valor alto / presente, azul = valor baixo / ausente).
    
-   As permiss√µes mais relevantes incluem:
    
    -   `SEND_SMS_1.0`, `READ_PHONE_STATE_1.0`, `READ_SMS_1.0`: quando **ativas (vermelhas)**, t√™m forte impacto positivo na classifica√ß√£o como **malware**, sugerindo comportamento malicioso.
        
    -   `GET_ACCOUNTS_1.0` e `ACCESS_NETWORK_STATE_1.0`: apresentam impacto misto, com comportamentos diferentes dependendo do contexto.
        
    -   Permiss√µes como `RECEIVE_BOOT_COMPLETED_1.0` e `WRITE_HISTORY_BOOKMARKS_1.0` tamb√©m contribuem, mas com menor intensidade.
        

Este gr√°fico permite concluir que o modelo **aprende padr√µes interpret√°veis** e condizentes com pr√°ticas conhecidas de malware, refor√ßando a confiabilidade e **explicabilidade** do processo de decis√£o. Al√©m disso, evidencia a import√¢ncia de um subconjunto reduzido de permiss√µes, o que pode auxiliar na **redu√ß√£o dimensional** e auditoria dos atributos usados.

### 5.2 An√°lise SHAP Force Plot
![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/shap_force_plot.png)

**Explica√ß√£o**:
Este gr√°fico visualiza como os valores das features influenciaram uma predi√ß√£o espec√≠fica do modelo. A previs√£o final (`f(x) = 5.94`) resulta da soma do valor base (m√©dia das predi√ß√µes) com os impactos acumulados de cada atributo.

**Interpreta√ß√£o:**

-   **Base value**: √© o valor m√©dio da sa√≠da do modelo sem considerar nenhuma feature (refer√™ncia neutra).
    
-   **Setas vermelhas (‚Üí higher)**: indicam features que **aumentaram** a probabilidade da amostra ser classificada como **malware**.
    
    -   `SEND_SMS_1.0`, `ACCESS_NETWORK_STATE_1.0` e `GET_ACCOUNTS_1.0` contribu√≠ram positivamente, impulsionando a predi√ß√£o para a classe maliciosa.
        
-   **Seta azul (‚Üí lower)**: representa uma feature que **reduziu** essa probabilidade.
    
    -   `WRITE_HISTORY_BOOKMARKS_1.0` teve um impacto negativo, atuando como um fator benigno.
        

O valor final de **5.94** est√° bem acima do limiar de decis√£o, refor√ßando que o modelo classificou esta inst√¢ncia com **alta confian√ßa como malware**.

### 5.3 An√°lise import√¢ncia das caracter√≠sticas LIME
![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/lime_feature_importance_20250701_232317.png)

**Explica√ß√£o**:
O gr√°fico apresenta a contribui√ß√£o individual de cada feature na decis√£o do modelo para uma **amostra espec√≠fica**, permitindo uma an√°lise **local** da explica√ß√£o. Os pesos indicam o quanto cada atributo influenciou a classifica√ß√£o:

-   **Barras azuis (positivas)**: caracter√≠sticas que **favoreceram a predi√ß√£o como malware**.
    
    -   Destaques:
        
        -   `SEND_SMS > -0.56` (peso: +0.242)
            
        -   `READ_PHONE_STATE > 0.76` (peso: +0.241)
            
        -   `INTERNET > 0.38` (peso: +0.241)  
            ‚Üí A presen√ßa ou valores altos dessas permiss√µes aumentaram significativamente a probabilidade de a amostra ser classificada como maliciosa.
            
-   **Barras vermelhas (negativas)**: caracter√≠sticas que **atuaram contra a classifica√ß√£o como malware**, ou seja, aproximaram a inst√¢ncia da classe benigna.
    
    -   Destaques:
        
        -   `WRITE_HISTORY_BOOKMARKS <= -0.22` (peso: ‚Äì0.224)
            
        -   `GET_ACCOUNTS <= 1.53` (peso: ‚Äì0.188)
            
        -   `READ_SMS <= -0.48` (peso: ‚Äì0.119)  
            ‚Üí Esses atributos, ao estarem ausentes ou abaixo de determinado valor, indicaram comportamento benigno ao modelo.
            

Este gr√°fico complementa a explica√ß√£o global do SHAP ao mostrar **como o modelo tomou uma decis√£o em um caso concreto**, oferecendo uma forma interpret√°vel e confi√°vel de justificar decis√µes individuais ‚Äî fundamental em contextos como ciberseguran√ßa e auditoria.

### 5.4 An√°lise Probabilidade de Predi√ß√£o LIME
![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/lime_interpretability.png)

**Insights**:
O gr√°fico mostra como as **features ativas** (valores fornecidos √† direita) impactaram a predi√ß√£o do modelo (barra central), contribuindo para a classifica√ß√£o como **malware (classe 1)** ou **benigno (classe 0)**.

#### üî∂ Principais contribui√ß√µes para **classe 1 (malware)**:

-   `READ_PHONE_STATE = 0.76`
    
-   `INTERNET = 0.39`
    
-   `SEND_SMS = 1.78`
    
-   `CHANGE_WIFI_MULTICAST_STATE = -0.12`
    

Estas permiss√µes s√£o **fortes indicativos de comportamento malicioso** e empurraram a predi√ß√£o para a classe ‚Äúmalware‚Äù.

#### üî∑ Principais contribui√ß√µes para **classe 0 (benigno)**:

-   `WRITE_HISTORY_BOOKMARKS = -0.30`
    
-   `GET_ACCOUNTS = -0.64`
    
-   `READ_CALL_LOG = -0.12`
    
-   `USE_CREDENTIALS = -0.33`
    
-   `READ_SMS = -0.48`
    
-   `MASTER_CLEAR = -0.11`
    

Essas permiss√µes, por estarem ausentes ou com valor baixo, puxaram a predi√ß√£o em dire√ß√£o √† classe benigna. Mesmo assim, o modelo atribuiu **alta probabilidade (‚âà 1.00)** para a classe malware, dado o maior peso das permiss√µes maliciosas.

## 6. Performance geral do Pipeline

### 5.2 Desempenho Tempo x RAM
![SHAP](https://raw.githubusercontent.com/JonerMello/MH-AutoML/main/doc/artifacts/performance_metrics.jpg)

**Insights**:
- No gr√°fico podemos identificar trade-off entre tempo de execu√ß√£o e consumo de memoria RAM em cada etapa do pipeline
- A etapa de extra√ß√£o de features √© a mais intensiva em mem√≥ria (8-12GB), mas relativamente r√°pida
- A otimiza√ß√£o de hiperpar√¢metros com Optuna consome mais tempo (15-20 min) mas mem√≥ria moderada
- A gera√ß√£o de gr√°ficos SHAP/LIME √© computacionalmente cara mas essencial para interpretabilidade
- O treinamento final do modelo √© eficiente em tempo e mem√≥ria
- Esta an√°lise foi crucial para otimizar o pipeline para diferentes ambientes de execu√ß√£o

## 6. üß† Discuss√£o Acad√™mica

### 6.1 Contribui√ß√µes
1. Framework reprodut√≠vel com AUC >0.99
2. Metodologia para an√°lise de bin√°rios ofuscados
3. Banco de features validado empiricamente
4. Sistema de interpretabilidade robusto com SHAP e LIME
5. Pipeline automatizado com controle de vers√µes e cache
6. Solu√ß√µes para incompatibilidades entre bibliotecas de interpretabilidade

### 6.2 Limita√ß√µes
- Depend√™ncia de an√°lise est√°tica
- Desempenho reduzido em malwares polim√≥rficos avan√ßados
- Necessidade de atualiza√ß√£o cont√≠nua do dataset
- Limita√ß√µes de interpretabilidade em modelos ensemble complexos
- Depend√™ncia de vers√µes espec√≠ficas de bibliotecas (SHAP v0.20+)

### 6.3 Trabalhos Futuros
- Integra√ß√£o com an√°lise din√¢mica
- Detec√ß√£o de zero-day attacks
- Modelos espec√≠ficos por fam√≠lia de malware
- Melhoria na interpretabilidade de modelos ensemble
- Adapta√ß√£o para diferentes arquiteturas de processadores
- Integra√ß√£o com sistemas de detec√ß√£o em tempo real