#!/usr/bin/env python3
"""
Script para listar todos os artefatos gerados pelo MH-AutoML
"""

import os
import glob
from datetime import datetime
from pathlib import Path

def list_artifacts():
    """Lista todos os artefatos gerados pelo MH-AutoML"""
    
    print("üìã LISTA COMPLETA DE ARTEFATOS - MH-AutoML")
    print("=" * 60)
    print(f"üìÖ Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìÅ Diret√≥rio: {os.getcwd()}")
    print()
    
    # Estrutura de se√ß√µes do MLflow
    sections = {
        "00_Data_info": "Informa√ß√µes sobre o dataset",
        "01_preprocessing": "Pr√©-processamento de dados", 
        "02_feature_engineering": "Engenharia e sele√ß√£o de features",
        "03_model_optimization": "Otimiza√ß√£o de hiperpar√¢metros",
        "04_evaluation_metrics": "M√©tricas e gr√°ficos de avalia√ß√£o",
        "05_interpretability": "Interpretabilidade do modelo",
        "MH_Best_Model": "Modelo final registrado",
        "report": "Relat√≥rios finais"
    }
    
    # Mapeamento de extens√µes para tipos
    extension_types = {
        '.png': 'Imagem',
        '.jpg': 'Imagem', 
        '.jpeg': 'Imagem',
        '.html': 'Relat√≥rio Interativo',
        '.csv': 'Dados',
        '.pkl': 'Modelo',
        '.pdf': 'Relat√≥rio PDF',
        '.yaml': 'Configura√ß√£o',
        '.json': 'Dados JSON',
        '.txt': 'Texto',
        '.log': 'Log'
    }
    
    total_artifacts = 0
    total_size = 0
    
    # Verificar pasta results
    results_path = Path("results")
    if not results_path.exists():
        print("‚ùå Pasta 'results' n√£o encontrada!")
        return
    
    print("üìä ARTEFATOS ENCONTRADOS:")
    print("-" * 60)
    
    # Listar todos os arquivos na pasta results
    all_files = list(results_path.rglob("*"))
    all_files = [f for f in all_files if f.is_file()]
    
    # Agrupar por tipo de arquivo
    files_by_extension = {}
    for file_path in all_files:
        ext = file_path.suffix.lower()
        if ext not in files_by_extension:
            files_by_extension[ext] = []
        files_by_extension[ext].append(file_path)
    
    # Mostrar estat√≠sticas por extens√£o
    print("üìà ESTAT√çSTICAS POR TIPO DE ARQUIVO:")
    print("-" * 40)
    
    for ext, files in sorted(files_by_extension.items()):
        file_type = extension_types.get(ext, 'Outro')
        total_size_ext = sum(f.stat().st_size for f in files)
        total_artifacts += len(files)
        total_size += total_size_ext
        
        print(f"üìÑ {ext.upper()} ({file_type}): {len(files)} arquivos - {total_size_ext / 1024:.1f} KB")
    
    print()
    print("üìã LISTA DETALHADA DE ARQUIVOS:")
    print("-" * 60)
    
    # Agrupar por categoria funcional
    categories = {
        "Gr√°ficos de Avalia√ß√£o": ["confusion_matrix", "roc_curve", "precision_recall_curve", 
                                 "probability_distribution", "metrics_by_class"],
        "Gr√°ficos de Otimiza√ß√£o": ["optuna_", "hyperparameters", "models_ranking"],
        "Gr√°ficos de Features": ["pca_", "lasso_", "anova_", "feature_importance"],
        "Gr√°ficos de Interpretabilidade": ["shap_", "lime_", "decision_tree"],
        "Gr√°ficos de Pr√©-processamento": ["missing_values", "clean_"],
        "Dados e Modelos": [".csv", ".pkl", "treino_", "features_selected"],
        "Relat√≥rios": [".html", ".pdf", "report_"],
        "Performance": ["performance_", "best_model_"]
    }
    
    for category, patterns in categories.items():
        category_files = []
        for file_path in all_files:
            file_name = file_path.name.lower()
            if any(pattern.lower() in file_name for pattern in patterns):
                category_files.append(file_path)
        
        if category_files:
            print(f"\nüéØ {category.upper()}:")
            for file_path in sorted(category_files):
                size = file_path.stat().st_size
                print(f"   üìÑ {file_path.name} ({size / 1024:.1f} KB)")
    
    # Mostrar arquivos n√£o categorizados
    categorized_files = set()
    for patterns in categories.values():
        for file_path in all_files:
            file_name = file_path.name.lower()
            if any(pattern.lower() in file_name for pattern in patterns):
                categorized_files.add(file_path)
    
    uncategorized = [f for f in all_files if f not in categorized_files]
    if uncategorized:
        print(f"\nüîç OUTROS ARQUIVOS:")
        for file_path in sorted(uncategorized):
            size = file_path.stat().st_size
            print(f"   üìÑ {file_path.name} ({size / 1024:.1f} KB)")
    
    print()
    print("üìä RESUMO FINAL:")
    print("-" * 40)
    print(f"üìÅ Total de artefatos: {total_artifacts}")
    print(f"üíæ Tamanho total: {total_size / (1024*1024):.2f} MB")
    print(f"üìÖ √öltima atualiza√ß√£o: {datetime.fromtimestamp(max(f.stat().st_mtime for f in all_files)).strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Verificar se h√° MLflow runs
    mlruns_path = Path("mlruns")
    if mlruns_path.exists():
        print(f"\nüîó MLflow runs encontrados em: {mlruns_path}")
        print("   Execute 'mlflow ui' para visualizar no navegador")
    
    print()
    print("‚úÖ Listagem conclu√≠da!")

def categorize_by_mlflow_section():
    """Categoriza artefatos por se√ß√£o do MLflow"""
    
    print("\nüóÇÔ∏è CATEGORIZA√á√ÉO POR SE√á√ÉO MLFLOW:")
    print("-" * 50)
    
    mlflow_sections = {
        "00_Data_info": ["dataset_info", "data_analysis"],
        "01_preprocessing": ["missing_values", "clean_", "preprocessing"],
        "02_feature_engineering": ["pca_", "lasso_", "anova_", "feature_", "treino_", "features_selected"],
        "03_model_optimization": ["optuna_", "hyperparameters", "models_ranking"],
        "04_evaluation_metrics": ["confusion_matrix", "roc_curve", "precision_recall", "probability_distribution", 
                                 "metrics_by_class", "performance_", "best_model_"],
        "05_interpretability": ["shap_", "lime_", "decision_tree"],
        "MH_Best_Model": ["model.pkl", "conda.yaml", "python_env.yaml", "MLmodel"],
        "report": ["report_", ".html", ".pdf"]
    }
    
    results_path = Path("results")
    if not results_path.exists():
        return
    
    all_files = list(results_path.rglob("*"))
    all_files = [f for f in all_files if f.is_file()]
    
    for section, patterns in mlflow_sections.items():
        section_files = []
        for file_path in all_files:
            file_name = file_path.name.lower()
            if any(pattern.lower() in file_name for pattern in patterns):
                section_files.append(file_path)
        
        if section_files:
            print(f"\nüìÇ {section}:")
            for file_path in sorted(section_files):
                size = file_path.stat().st_size
                print(f"   üìÑ {file_path.name} ({size / 1024:.1f} KB)")

if __name__ == "__main__":
    list_artifacts()
    categorize_by_mlflow_section() 