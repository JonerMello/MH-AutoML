# Gr√°ficos de Avalia√ß√£o - Se√ß√£o 04_evaluation_metrics

Este documento descreve todos os gr√°ficos de avalia√ß√£o que s√£o gerados automaticamente e salvos na se√ß√£o `04_evaluation_metrics` do MLflow.

## üìä Gr√°ficos Dispon√≠veis

### 1. Matriz de Confus√£o (`confusion_matrix.png`)
- **Descri√ß√£o**: Mostra a matriz de confus√£o com valores absolutos
- **Classes**: Benign (0) e Malware (1)
- **Visualiza√ß√£o**: Heatmap com cores azuis
- **Informa√ß√µes**: Verdadeiros positivos, falsos positivos, verdadeiros negativos, falsos negativos

### 2. Curva ROC/AUC (`roc_curve.png`)
- **Descri√ß√£o**: Curva ROC (Receiver Operating Characteristic) com valor AUC
- **Eixo X**: False Positive Rate (1 - Especificidade)
- **Eixo Y**: True Positive Rate (Sensibilidade)
- **Linha de refer√™ncia**: Linha diagonal (AUC = 0.5)
- **Informa√ß√µes**: Valor AUC calculado automaticamente

### 3. Curva Precis√£o-Recall (`precision_recall_curve.png`)
- **Descri√ß√£o**: Curva de precis√£o vs recall com Average Precision (AP)
- **Eixo X**: Recall (Sensibilidade)
- **Eixo Y**: Precis√£o
- **Linha de refer√™ncia**: Linha horizontal em y=1 (precis√£o perfeita)
- **Informa√ß√µes**: Valor AP (Average Precision) calculado automaticamente

### 4. Distribui√ß√£o de Probabilidades (`probability_distribution.png`)
- **Descri√ß√£o**: Histograma das probabilidades preditas por classe real
- **Classes**: Benign (azul) e Malware (vermelho)
- **Linha de refer√™ncia**: Limiar de decis√£o em 0.5
- **Informa√ß√µes**: Densidade de probabilidades para cada classe

### 5. M√©tricas por Classe (`metrics_by_class.png`)
- **Descri√ß√£o**: Gr√°fico de barras com m√©tricas de performance por classe
- **M√©tricas**: Precis√£o, Recall e F1-Score
- **Classes**: Benign e Malware
- **Informa√ß√µes**: Valores num√©ricos exibidos nas barras

## üîß Como s√£o Gerados

Os gr√°ficos s√£o gerados automaticamente no m√©todo `evaluate_model()` da classe `Core`:

```python
def evaluate_model(self, model, X_test, y_test):
    # ... c√≥digo existente ...
    
    # Gerar gr√°ficos de avalia√ß√£o
    self._generate_evaluation_plots(y_test, y_pred, y_pred_proba)
    
    return report, y_test, y_pred
```

## üìÅ Localiza√ß√£o no MLflow

Todos os gr√°ficos s√£o salvos em:
- **Pasta local**: `results/`
- **Se√ß√£o MLflow**: `04_evaluation_metrics/`

## üéØ Utilidade dos Gr√°ficos

### Para Detec√ß√£o de Malware:
1. **Matriz de Confus√£o**: Identificar falsos positivos e falsos negativos
2. **Curva ROC**: Avaliar capacidade discriminativa geral do modelo
3. **Curva PR**: Especialmente √∫til para dados desbalanceados
4. **Distribui√ß√£o de Probabilidades**: Verificar separa√ß√£o entre classes
5. **M√©tricas por Classe**: Comparar performance entre benign e malware

### Para An√°lise de Performance:
- **AUC > 0.9**: Excelente discrimina√ß√£o
- **AUC 0.8-0.9**: Boa discrimina√ß√£o
- **AUC 0.7-0.8**: Discrimina√ß√£o aceit√°vel
- **AUC < 0.7**: Discrimina√ß√£o pobre

## üöÄ Execu√ß√£o

Os gr√°ficos s√£o gerados automaticamente durante a execu√ß√£o do pipeline:

```bash
python -c "from controller.core import Core; core = Core('Datasets/android_permissions.csv', 'class'); core.run()"
```

## üìã Teste dos Gr√°ficos

Para testar a gera√ß√£o dos gr√°ficos:

```bash
python test/test_all_evaluation_plots.py
```

## üìà M√©tricas Adicionais Logadas

Al√©m dos gr√°ficos, as seguintes m√©tricas s√£o logadas no MLflow:

- `accuracy`: Acur√°cia geral
- `precision`: Precis√£o macro-m√©dia
- `recall`: Recall macro-m√©dia
- `f1`: F1-score macro-m√©dia
- `mcc`: Coeficiente de correla√ß√£o de Matthews
- `roc_auc`: √Årea sob a curva ROC
- `average_precision`: Precis√£o m√©dia
- `f2_score`: F2-score (d√° mais peso ao recall)
- `true_positive_rate`: Taxa de verdadeiros positivos
- `false_alarm_ratio`: Raz√£o de falsos alarmes

## üîç Interpreta√ß√£o

### Para Detec√ß√£o de Malware:
- **Alto Recall**: Importante para n√£o perder malware
- **Alta Precis√£o**: Importante para reduzir falsos positivos
- **AUC Alto**: Indica boa capacidade discriminativa
- **Distribui√ß√£o Separada**: Probabilidades bem separadas entre classes

### Sinais de Problemas:
- **AUC Baixo**: Modelo n√£o consegue discriminar bem
- **Distribui√ß√£o Sobreposta**: Probabilidades muito similares entre classes
- **Recall Baixo**: Muitos malwares n√£o detectados
- **Precis√£o Baixa**: Muitos falsos positivos 